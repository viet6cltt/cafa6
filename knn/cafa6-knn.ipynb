{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"},{"sourceId":13990998,"sourceType":"datasetVersion","datasetId":8917141},{"sourceId":13991073,"sourceType":"datasetVersion","datasetId":8917158},{"sourceId":14073266,"sourceType":"datasetVersion","datasetId":8916743}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install faiss-cpu\n\nimport faiss\nprint(faiss.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T22:20:26.417608Z","iopub.execute_input":"2025-12-09T22:20:26.417936Z","iopub.status.idle":"2025-12-09T22:20:34.439082Z","shell.execute_reply.started":"2025-12-09T22:20:26.417912Z","shell.execute_reply":"2025-12-09T22:20:34.438163Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.13.1\n1.13.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport faiss\nfrom tqdm import tqdm\nimport os\nimport gc\n\n# ============================================================================\n# C·∫§U H√åNH K·ª∏ THU·∫¨T (STRICT MODE)\n# ============================================================================\nCONFIG = {\n    'EMBED_DIR': \"/kaggle/input/cafa6-embeds\", \n    'TRAIN_TERMS': \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\",\n    'TRAIN_IDS': \"/kaggle/input/cafa6-embeds/train_ids.txt\",\n    'TEST_IDS': \"/kaggle/input/cafa6-embeds/test_ids.txt\",\n    \n    'K_NEIGHBORS': 10,       # K nh·ªè\n    'HOMOLOGY_THRESHOLD': 0.85, \n    'MIN_TERM_VOTES': 2,\n    \n    'BATCH_SIZE': 1000,\n}\n\ndef run_consensus_knn_miner():\n    print(\"üöÄ STARTING CONSENSUS HOMOLOGY MINER (FAISS CPU)...\")\n    \n    # 1. Load Data & Embeddings (Gi·ªØ nguy√™n nh∆∞ tr∆∞·ªõc)\n    print(\"   1. Loading Resources...\")\n    df = pd.read_csv(CONFIG['TRAIN_TERMS'], sep='\\t', usecols=['EntryID', 'term'])\n    labels_dict = df.groupby('EntryID')['term'].apply(list).to_dict()\n    del df; gc.collect()\n\n    with open(CONFIG['TRAIN_IDS']) as f: train_ids = np.array([l.strip() for l in f])\n    with open(CONFIG['TEST_IDS']) as f: test_ids = np.array([l.strip() for l in f])\n    \n    X_train = np.load(os.path.join(CONFIG['EMBED_DIR'], \"train_embeds.npy\")).astype('float32')\n    X_test = np.load(os.path.join(CONFIG['EMBED_DIR'], \"test_embeds.npy\")).astype('float32')\n    \n    faiss.normalize_L2(X_train)\n    faiss.normalize_L2(X_test)\n\n    # 2. Build Index\n    print(\"   2. Building FAISS Index...\")\n    index = faiss.IndexFlatIP(X_train.shape[1])\n    index.add(X_train)\n    del X_train; gc.collect()\n\n    # 3. Search & Filter (LOGIC C·∫¨P NH·∫¨T)\n    print(f\"   3. Mining with Consensus Check...\")\n    output_file = \"knn_homology_candidates.tsv\"\n    \n    with open(output_file, \"w\") as f_out:\n        for i in tqdm(range(0, X_test.shape[0], CONFIG['BATCH_SIZE'])):\n            batch_test = X_test[i : i + CONFIG['BATCH_SIZE']]\n            D, I = index.search(batch_test, CONFIG['K_NEIGHBORS'])\n            \n            batch_lines = []\n            \n            for j in range(len(batch_test)):\n                # L·ªçc ngay t·ª´ ƒë·∫ßu: H√†ng x√≥m th·ª© 2 ph·∫£i x·ªãn (Sim > 0.85)\n                # N·∫øu kh√¥ng th√¨ ch·∫Øc ch·∫Øn kh√¥ng ƒë·ªß 2 vote\n                if D[j, 1] < CONFIG['HOMOLOGY_THRESHOLD']: continue\n                \n                pid = test_ids[i + j]\n                term_scores = {} # T·ªïng ƒëi·ªÉm sim\n                term_votes = {}  # ƒê·∫øm s·ªë ng∆∞·ªùi vote\n                \n                # Duy·ªát qua c√°c h√†ng x√≥m\n                for k in range(CONFIG['K_NEIGHBORS']):\n                    sim = float(D[j, k])\n                    if sim < CONFIG['HOMOLOGY_THRESHOLD']: break \n                    \n                    neighbor_pid = train_ids[I[j, k]]\n                    terms = labels_dict.get(neighbor_pid, [])\n                    \n                    for t in terms:\n                        term_scores[t] = term_scores.get(t, 0.0) + sim\n                        term_votes[t] = term_votes.get(t, 0) + 1\n                \n                if not term_scores: continue\n                \n                # L·ªçc v√† Ghi\n                valid_terms = []\n                for t, raw_sum in term_scores.items():\n                    votes = term_votes[t]\n                    \n                    # [QUAN TR·ªåNG] Ch·ªâ l·∫•y nh√£n c√≥ >= 2 ng∆∞·ªùi vote\n                    if votes < CONFIG['MIN_TERM_VOTES']: continue\n                    \n                    # T√≠nh ƒëi·ªÉm trung b√¨nh c·ªßa nh·ªØng ng∆∞·ªùi vote\n                    # V√≠ d·ª•: 2 ng∆∞·ªùi vote (0.9, 0.88) -> Avg = 0.89 (R·∫•t cao)\n                    avg_score = raw_sum / votes\n                    \n                    # Ch·∫∑n d∆∞·ªõi l·∫ßn cu·ªëi (ƒë·ªÉ ch·∫Øc ch·∫Øn kh√¥ng c√≥ r√°c)\n                    if avg_score >= 0.85:\n                        valid_terms.append((t, avg_score))\n                \n                # Sort l·∫•y top (ch·ªâ c·∫ßn l·∫•y √≠t th√¥i v√¨ ƒë√¢y l√† Homology m·∫°nh)\n                valid_terms.sort(key=lambda x: x[1], reverse=True)\n                \n                for term, score in valid_terms[:50]:\n                    batch_lines.append(f\"{pid}\\t{term}\\t{score:.4f}\\n\")\n            \n            f_out.write(\"\".join(batch_lines))\n            \n    print(f\"‚úÖ DONE! Consensus Candidates saved to {output_file}\")\n\nif __name__ == \"__main__\":\n    run_consensus_knn_miner()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T22:20:34.441253Z","iopub.execute_input":"2025-12-09T22:20:34.441612Z","iopub.status.idle":"2025-12-09T22:28:22.260948Z","shell.execute_reply.started":"2025-12-09T22:20:34.441578Z","shell.execute_reply":"2025-12-09T22:28:22.259896Z"}},"outputs":[{"name":"stdout","text":"üöÄ STARTING CONSENSUS HOMOLOGY MINER (FAISS CPU)...\n   1. Loading Resources...\n   2. Building FAISS Index...\n   3. Mining with Consensus Check...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [07:34<00:00,  2.02s/it]","output_type":"stream"},{"name":"stdout","text":"‚úÖ DONE! Consensus Candidates saved to knn_homology_candidates.tsv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# C·∫§U H√åNH\nKNN_FILE = \"knn_homology_candidates.tsv\"\nIA_FILE = \"/kaggle/input/cafa-6-protein-function-prediction/IA.tsv\"\n\ndef analyze_knn_candidates():\n    print(f\"üìä ANALYZING {KNN_FILE}...\\n\")\n    \n    # 1. Load Data\n    try:\n        df = pd.read_csv(KNN_FILE, sep='\\t', names=['pid', 'term', 'score'])\n    except FileNotFoundError:\n        print(\"‚ùå Error: File not found!\")\n        return\n    except pd.errors.EmptyDataError:\n        print(\"‚ö†Ô∏è Warning: File is EMPTY! (Threshold qu√° g·∫Øt, kh√¥ng t√¨m th·∫•y h√†ng x√≥m n√†o).\")\n        return\n\n    # 2. Load IA\n    print(\"   Loading IA weights...\")\n    ia_map = {}\n    try:\n        with open(IA_FILE, 'r') as f:\n            for line in f:\n                p = line.strip().split('\\t')\n                if len(p) >= 2: ia_map[p[0]] = float(p[1])\n    except: pass\n    \n    # Map IA v√†o DataFrame\n    df['ia'] = df['term'].map(ia_map).fillna(0)\n    \n   # =========================================================================\n    # 3. B√ÅO C√ÅO TH·ªêNG K√ä (C·∫¨P NH·∫¨T: IA THEO KHO·∫¢NG CHI TI·∫æT)\n    # =========================================================================\n    \n    n_prots = df['pid'].nunique()\n    n_terms = df['term'].nunique()\n    n_rows = len(df)\n    \n    print(\"-\" * 40)\n    print(f\"üîπ T·ªîNG QUAN:\")\n    print(f\"   - T·ªïng s·ªë d√≤ng (Predictions): {n_rows:,}\")\n    print(f\"   - S·ªë Protein ƒë∆∞·ª£c 'C·ª©u' (Covered): {n_prots:,}\")\n    print(f\"   - S·ªë Nh√£n GO xu·∫•t hi·ªán: {n_terms:,}\")\n    print(f\"   - Trung b√¨nh s·ªë nh√£n/protein: {n_rows / n_prots:.1f}\")\n    \n    print(\"-\" * 40)\n    print(f\"üîπ PH√ÇN PH·ªêI ƒêI·ªÇM S·ªê (SCORE):\")\n    print(df['score'].describe().to_string())\n    print(f\"\\n   -> Min Score check: {df['score'].min():.4f} (Ph·∫£i >= 0.85 n·∫øu code ƒë√∫ng)\")\n    \n    print(\"-\" * 40)\n    print(\"üîπ PH√ÇN B·ªê ƒê·ªò HI·∫æM (IA) THEO KHO·∫¢NG:\")\n    \n    # ƒê·ªãnh nghƒ©a c√°c bins IA\n    bins = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1e9]\n    labels = [\n        \"IA == 0\",\n        \"0 ‚Üí 1\",\n        \"1 ‚Üí 2\",\n        \"2 ‚Üí 3\",\n        \"3 ‚Üí 4\",\n        \"4 ‚Üí 5\",\n        \"5 ‚Üí 6\",\n        \"6 ‚Üí 7\",\n        \"7 ‚Üí 8\",\n        \"8 ‚Üí 9\",\n        \"9 ‚Üí 10\",\n        \"> 10\"\n    ]\n    \n    df['ia_bin'] = pd.cut(df['ia'], bins=bins, labels=labels)\n    \n    ia_dist = df['ia_bin'].value_counts().sort_index()\n\n    for k in labels:\n        count = ia_dist.get(k, 0)\n        ratio = count / n_rows * 100\n        print(f\"   {k:8s} : {count:10,}  |  {ratio:6.2f} %\")\n    \n    # =========================================================================\n    # 4. ƒê√ÅNH GI√Å (VERDICT)\n    # =========================================================================\n    \n    print(\"-\" * 40)\n    print(\"üöÄ ƒê√ÅNH GI√Å KH·∫¢ NƒÇNG ENSEMBLE:\")\n    \n    # Ti√™u ch√≠ 1: Min Score\n    if df['score'].min() < 0.84:\n        print(\"‚ùå C·∫¢NH B√ÅO: C√≥ ƒëi·ªÉm s·ªë th·∫•p (< 0.85). Code l·ªçc ch∆∞a chu·∫©n!\")\n    else:\n        print(\"‚úÖ Score Quality: T·ªët (To√†n b·ªô l√† Homology m·∫°nh).\")\n    \n    # T√≠nh Tail theo IA >= 5\n    tail = df[df['ia'] >= 5]\n    super_rare = df[df['ia'] >= 10]\n    \n    tail_ratio = len(tail) / n_rows\n    super_ratio = len(super_rare) / n_rows\n    \n    print(f\"   - TAIL (IA ‚â• 5)      : {len(tail):,}  |  {tail_ratio:.2%}\")\n    print(f\"   - SUPER RARE (IA ‚â•10): {len(super_rare):,}  |  {super_ratio:.2%}\")\n    \n    if tail_ratio > 0.2:\n        print(\"‚úÖ Rarity: T·ªët. KNN t·∫≠p trung ƒë√∫ng v√πng nh√£n hi·∫øm.\")\n    else:\n        print(\"‚ö†Ô∏è Rarity: Th·∫•p. KNN v·∫´n thi√™n nhi·ªÅu v·ªÅ head.\")\n    \n    # ƒê√°nh gi√° Coverage\n    if n_prots < 500:\n        print(\"‚ö†Ô∏è Coverage: R·∫•t th·∫•p (< 500 proteins). Ng∆∞·ª°ng ƒëang qu√° g·∫Øt.\")\n    elif n_prots > 50000:\n        print(\"‚ö†Ô∏è Coverage: R·∫•t cao. KNN ƒëang ph·ªß qu√° r·ªông.\")\n    else:\n        print(f\"‚úÖ Coverage: H·ª£p l√Ω ({n_prots:,} proteins c√≥ h√†ng x√≥m x·ªãn).\")\n\nif __name__ == \"__main__\":\n    analyze_knn_candidates()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T22:28:22.261859Z","iopub.execute_input":"2025-12-09T22:28:22.262146Z","iopub.status.idle":"2025-12-09T22:28:24.898626Z","shell.execute_reply.started":"2025-12-09T22:28:22.262081Z","shell.execute_reply":"2025-12-09T22:28:24.897761Z"}},"outputs":[{"name":"stdout","text":"üìä ANALYZING knn_homology_candidates.tsv...\n\n   Loading IA weights...\n----------------------------------------\nüîπ T·ªîNG QUAN:\n   - T·ªïng s·ªë d√≤ng (Predictions): 2,006,071\n   - S·ªë Protein ƒë∆∞·ª£c 'C·ª©u' (Covered): 223,968\n   - S·ªë Nh√£n GO xu·∫•t hi·ªán: 14,504\n   - Trung b√¨nh s·ªë nh√£n/protein: 9.0\n----------------------------------------\nüîπ PH√ÇN PH·ªêI ƒêI·ªÇM S·ªê (SCORE):\ncount    2.006071e+06\nmean     9.845593e-01\nstd      1.455886e-02\nmin      8.505000e-01\n25%      9.797000e-01\n50%      9.884000e-01\n75%      9.942000e-01\nmax      1.000000e+00\n\n   -> Min Score check: 0.8505 (Ph·∫£i >= 0.85 n·∫øu code ƒë√∫ng)\n----------------------------------------\nüîπ PH√ÇN B·ªê ƒê·ªò HI·∫æM (IA) THEO KHO·∫¢NG:\n   IA == 0  :    198,370  |    9.89 %\n   0 ‚Üí 1    :  1,014,524  |   50.57 %\n   1 ‚Üí 2    :    341,029  |   17.00 %\n   2 ‚Üí 3    :    167,992  |    8.37 %\n   3 ‚Üí 4    :    117,108  |    5.84 %\n   4 ‚Üí 5    :     54,426  |    2.71 %\n   5 ‚Üí 6    :     45,386  |    2.26 %\n   6 ‚Üí 7    :     21,273  |    1.06 %\n   7 ‚Üí 8    :     21,836  |    1.09 %\n   8 ‚Üí 9    :     14,881  |    0.74 %\n   9 ‚Üí 10   :      4,369  |    0.22 %\n   > 10     :      4,877  |    0.24 %\n----------------------------------------\nüöÄ ƒê√ÅNH GI√Å KH·∫¢ NƒÇNG ENSEMBLE:\n‚úÖ Score Quality: T·ªët (To√†n b·ªô l√† Homology m·∫°nh).\n   - TAIL (IA ‚â• 5)      : 112,659  |  5.62%\n   - SUPER RARE (IA ‚â•10): 4,877  |  0.24%\n‚ö†Ô∏è Rarity: Th·∫•p. KNN v·∫´n thi√™n nhi·ªÅu v·ªÅ head.\n‚ö†Ô∏è Coverage: R·∫•t cao. KNN ƒëang ph·ªß qu√° r·ªông.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom collections import defaultdict\nfrom tqdm import tqdm\n\n# =============================================================================\n# 1. C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N & THAM S·ªê\n# =============================================================================\nCONFIG = {\n    # File KNN Homology Candidate c·ªßa b·∫°n\n    'KNN_FILE': \"knn_homology_candidates.tsv\",\n    \n    # File Vocab c·ªßa hai m√¥ h√¨nh ch√≠nh\n    'VOCAB_C95_PATH': \"/kaggle/input/c95-cafa6/vocab_C95_remove.csv\", # Gi·∫£ ƒë·ªãnh C95 l√† d√πng to√†n b·ªô nh√£n\n    'VOCAB_C99_PATH': \"/kaggle/input/c99-cafa6/vocab_C99_remove.csv\", # C99 Vocab c·ªßa b·∫°n\n    \n    # File IA\n    'IA_FILE_PATH': \"/kaggle/input/cafa-6-protein-function-prediction/IA.tsv\", \n}\n\n# =============================================================================\n# 2. H√ÄM X·ª¨ L√ù D·ªÆ LI·ªÜU\n# =============================================================================\n\ndef load_terms_set(path, term_col='term'):\n    \"\"\"T·∫£i file Vocab ho·∫∑c Term list v√† tr·∫£ v·ªÅ m·ªôt Set ch·ª©a c√°c GO Terms.\"\"\"\n    try:\n        if path.endswith('.tsv') or path.endswith('.txt'):\n            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p C95 d√πng file train_terms g·ªëc\n            df = pd.read_csv(path, sep='\\t', usecols=['term'])\n        elif path.endswith('.csv'):\n            df = pd.read_csv(path, usecols=[term_col])\n        else:\n            print(f\"Warning: Unknown file type for {path}\")\n            return set()\n        \n        # X√≥a c√°c gi√° tr·ªã tr√πng l·∫∑p v√† nan\n        return set(df[term_col].dropna().unique())\n        \n    except FileNotFoundError:\n        print(f\"‚ùå ERROR: Kh√¥ng t√¨m th·∫•y file Vocabulary t·∫°i {path}\")\n        return set()\n    except Exception as e:\n        print(f\"‚ùå ERROR: L·ªói khi t·∫£i file {path}: {e}\")\n        return set()\n\ndef load_ia_map(path):\n    \"\"\"T·∫£i file IA v√† tr·∫£ v·ªÅ dictionary {term: IA_value}.\"\"\"\n    ia_map = {}\n    try:\n        # File IA th∆∞·ªùng l√† TSV (GO_ID \\t IA_value)\n        with open(path, 'r') as f:\n            for line in f:\n                parts = line.strip().split('\\t')\n                if len(parts) == 2:\n                    try:\n                        ia_map[parts[0]] = float(parts[1])\n                    except ValueError:\n                        continue # B·ªè qua header ho·∫∑c d√≤ng l·ªói\n    except FileNotFoundError:\n        print(f\"‚ùå ERROR: Kh√¥ng t√¨m th·∫•y file IA t·∫°i {path}\")\n    return ia_map\n\ndef get_ia_range(ia_value):\n    \"\"\"Ph√¢n lo·∫°i IA v√†o c√°c kho·∫£ng ƒë√£ ƒë·ªãnh.\"\"\"\n    if ia_value < 4: return '0_to_4_HEAD' # Kh√¥ng quan t√¢m\n    if ia_value < 5: return '4_to_5'\n    if ia_value < 6: return '5_to_6'\n    if ia_value < 7: return '6_to_7'\n    if ia_value < 8: return '7_to_8'\n    if ia_value < 9: return '8_to_9'\n    if ia_value < 10: return '9_to_10'\n    return '>10_SUPER_TAIL'\n\n# =============================================================================\n# 3. PH√ÇN T√çCH ƒê√ìNG G√ìP ƒê·ªòC QUY·ªÄN C·ª¶A KNN\n# =============================================================================\n\ndef analyze_unique_contribution():\n    print(\"üöÄ B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH ƒê√ìNG G√ìP ƒê·ªòC QUY·ªÄN C·ª¶A KNN...\")\n    \n    # --- B∆Ø·ªöC 1: T·∫£i D·ªØ li·ªáu ---\n    set_c95 = load_terms_set(CONFIG['VOCAB_C95_PATH'], term_col='term')\n    set_c99 = load_terms_set(CONFIG['VOCAB_C99_PATH'], term_col='term')\n    ia_map = load_ia_map(CONFIG['IA_FILE_PATH'])\n    \n    try:\n        # Load KNN file, GI·ªÆ C·∫¢ SCORE ƒë·ªÉ l·ªçc theo ng∆∞·ª°ng 0.90\n        knn_df = pd.read_csv(\n            CONFIG['KNN_FILE'],\n            sep='\\t',\n            names=['pid', 'term', 'score']\n        )\n    except FileNotFoundError:\n        print(f\"‚ùå ERROR: Kh√¥ng t√¨m th·∫•y file KNN Candidates t·∫°i {CONFIG['KNN_FILE']}\")\n        return\n    \n    # ======================= üî• L·ªåC THEO NG∆Ø·ª†NG 0.90 üî• =======================\n    knn_df = knn_df[knn_df['score'] >= 0.90]\n    \n    print(f\"   -> Sau khi l·ªçc score >= 0.90:\")\n    print(f\"      - S·ªë d√≤ng c√≤n l·∫°i: {len(knn_df):,}\")\n    print(f\"      - S·ªë protein c√≤n l·∫°i: {knn_df['pid'].nunique():,}\")\n    \n    # L·∫•y t·∫≠p h·ª£p c√°c nh√£n duy nh·∫•t m√† KNN t√¨m th·∫•y (sau l·ªçc)\n    set_knn = set(knn_df['term'].unique())\n    print(f\"      - S·ªë nh√£n GO duy nh·∫•t c√≤n l·∫°i: {len(set_knn):,}\")\n\n    # --- B∆Ø·ªöC 2: Kh·ªüi t·∫°o B·ªô ƒë·∫øm ---\n    # B·ªô ƒë·∫øm s·∫Ω ƒë·∫øm s·ªë l∆∞·ª£ng nh√£n (ƒë·ªôc l·∫≠p v·ªõi s·ªë l·∫ßn d·ª± ƒëo√°n)\n    # Kh√≥a: Kho·∫£ng IA (v√≠ d·ª•: '5_to_6')\n    # Gi√° tr·ªã: List c√°c GO term thu·ªôc lo·∫°i ƒë√≥\n    \n    unique_counts = {\n        'C95_Missing': defaultdict(list),  # Nh√£n kh√¥ng c√≥ trong C95\n        'C99_Missing': defaultdict(list),  # Nh√£n kh√¥ng c√≥ trong C99\n    }\n    \n    # --- B∆Ø·ªöC 3: Loop v√† Ph√¢n lo·∫°i ---\n    \n    # Ch·ªâ duy·ªát qua c√°c nh√£n m√† KNN t√¨m th·∫•y\n    for term in tqdm(set_knn, desc=\"Ph√¢n lo·∫°i nh√£n\"):\n        ia_value = ia_map.get(term, 0.0) # N·∫øu kh√¥ng c√≥ IA th√¨ m·∫∑c ƒë·ªãnh l√† 0.0\n        ia_range = get_ia_range(ia_value)\n        \n        # 1. Ki·ªÉm tra Nh√£n M·∫•t (Missing) kh·ªèi C95\n        if term not in set_c95:\n            unique_counts['C95_Missing'][ia_range].append(term)\n            \n        # 2. Ki·ªÉm tra Nh√£n M·∫•t (Missing) kh·ªèi C99\n        if term not in set_c99:\n            unique_counts['C99_Missing'][ia_range].append(term)\n\n\n    # --- B∆Ø·ªöC 4: B√°o c√°o k·∫øt qu·∫£ ---\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"  üèÜ ƒê√ìNG G√ìP ƒê·ªòC QUY·ªÄN C·ª¶A KNN (THEO ƒê·ªò HI·∫æM IA)\")\n    print(\"=\" * 60)\n    \n    print(\"\\n--- A. NH√ÉN KH√îNG C√ì TRONG C95 (C95 Missing) ---\")\n    \n    headers = [\"Kho·∫£ng IA\", \"S·ªë nh√£n ƒê·ªòC QUY·ªÄN\", \"T·ª∑ l·ªá (%)\"]\n    data_c95 = []\n    \n    total_c95_missing = sum(len(v) for k, v in unique_counts['C95_Missing'].items() if k != '0_to_4_HEAD')\n\n    for ia_range in ['4_to_5', '5_to_6', '6_to_7', '7_to_8', '8_to_9', '9_to_10', '>10_SUPER_TAIL']:\n        count = len(unique_counts['C95_Missing'][ia_range])\n        percent = (count / total_c95_missing) * 100 if total_c95_missing else 0\n        data_c95.append([ia_range, f\"{count:,}\", f\"{percent:.2f}%\"])\n\n    print(pd.DataFrame(data_c95, columns=headers).to_markdown(index=False))\n    print(f\"\\n   -> T·ªïng s·ªë nh√£n hi·∫øm (IA >= 4) m√† C95 b·ªè qua: {total_c95_missing:,}\\n\")\n\n\n    print(\"--- B. NH√ÉN KH√îNG C√ì TRONG C99 (C99 Missing) ---\")\n\n    headers = [\"Kho·∫£ng IA\", \"S·ªë nh√£n ƒê·ªòC QUY·ªÄN\", \"T·ª∑ l·ªá (%)\"]\n    data_c99 = []\n    \n    total_c99_missing = sum(len(v) for k, v in unique_counts['C99_Missing'].items() if k != '0_to_4_HEAD')\n\n    for ia_range in ['4_to_5', '5_to_6', '6_to_7', '7_to_8', '8_to_9', '9_to_10', '>10_SUPER_TAIL']:\n        count = len(unique_counts['C99_Missing'][ia_range])\n        percent = (count / total_c99_missing) * 100 if total_c99_missing else 0\n        data_c99.append([ia_range, f\"{count:,}\", f\"{percent:.2f}%\"])\n\n    print(pd.DataFrame(data_c99, columns=headers).to_markdown(index=False))\n    print(f\"\\n   -> T·ªïng s·ªë nh√£n hi·∫øm (IA >= 4) m√† C99 b·ªè qua: {total_c99_missing:,}\\n\")\n\nif __name__ == \"__main__\":\n    analyze_unique_contribution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T22:28:24.899966Z","iopub.execute_input":"2025-12-09T22:28:24.900329Z","iopub.status.idle":"2025-12-09T22:28:26.247515Z","shell.execute_reply.started":"2025-12-09T22:28:24.900300Z","shell.execute_reply":"2025-12-09T22:28:26.246470Z"}},"outputs":[{"name":"stdout","text":"üöÄ B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH ƒê√ìNG G√ìP ƒê·ªòC QUY·ªÄN C·ª¶A KNN...\n   -> Sau khi l·ªçc score >= 0.90:\n      - S·ªë d√≤ng c√≤n l·∫°i: 2,001,441\n      - S·ªë protein c√≤n l·∫°i: 223,835\n      - S·ªë nh√£n GO duy nh·∫•t c√≤n l·∫°i: 14,504\n","output_type":"stream"},{"name":"stderr","text":"Ph√¢n lo·∫°i nh√£n: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14504/14504 [00:00<00:00, 847780.50it/s]","output_type":"stream"},{"name":"stdout","text":"\n============================================================\n  üèÜ ƒê√ìNG G√ìP ƒê·ªòC QUY·ªÄN C·ª¶A KNN (THEO ƒê·ªò HI·∫æM IA)\n============================================================\n\n--- A. NH√ÉN KH√îNG C√ì TRONG C95 (C95 Missing) ---\n| Kho·∫£ng IA      |   S·ªë nh√£n ƒê·ªòC QUY·ªÄN | T·ª∑ l·ªá (%)   |\n|:---------------|--------------------:|:------------|\n| 4_to_5         |                 671 | 26.82%      |\n| 5_to_6         |                 536 | 21.42%      |\n| 6_to_7         |                 447 | 17.87%      |\n| 7_to_8         |                 346 | 13.83%      |\n| 8_to_9         |                 221 | 8.83%       |\n| 9_to_10        |                 112 | 4.48%       |\n| >10_SUPER_TAIL |                 169 | 6.75%       |\n\n   -> T·ªïng s·ªë nh√£n hi·∫øm (IA >= 4) m√† C95 b·ªè qua: 2,502\n\n--- B. NH√ÉN KH√îNG C√ì TRONG C99 (C99 Missing) ---\n| Kho·∫£ng IA      |   S·ªë nh√£n ƒê·ªòC QUY·ªÄN | T·ª∑ l·ªá (%)   |\n|:---------------|--------------------:|:------------|\n| 4_to_5         |                 369 | 26.51%      |\n| 5_to_6         |                 299 | 21.48%      |\n| 6_to_7         |                 229 | 16.45%      |\n| 7_to_8         |                 182 | 13.07%      |\n| 8_to_9         |                 141 | 10.13%      |\n| 9_to_10        |                  84 | 6.03%       |\n| >10_SUPER_TAIL |                  88 | 6.32%       |\n\n   -> T·ªïng s·ªë nh√£n hi·∫øm (IA >= 4) m√† C99 b·ªè qua: 1,392\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}