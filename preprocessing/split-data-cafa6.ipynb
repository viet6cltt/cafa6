{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"},{"sourceId":13989811,"sourceType":"datasetVersion","datasetId":8916743},{"sourceId":13989893,"sourceType":"datasetVersion","datasetId":8908959},{"sourceId":13990012,"sourceType":"datasetVersion","datasetId":8916833}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport os\nfrom sklearn.model_selection import train_test_split\n\n# ========================================================\n# âš™ï¸ Cáº¤U HÃŒNH \n# ========================================================\n# 1. Nguá»“n Labels \nLABEL_DIR = \"/kaggle/input/go-cafa6\"\n# 2. Nguá»“n Embeddings\nEMBED_DIR = \"/kaggle/input/cafa6-embeds\"\nTRAIN_IDS_FILE = os.path.join(EMBED_DIR, \"train_ids.txt\")\n# 3. Chia táº­p\nVAL_SIZE = 0.1  # 10% cho Validation\nSEED = 42\n\n# =========================================================\n# HÃ€M Xá»¬ LÃ CHÃNH: Táº O TARGETS & SPLIT (CHáº Y 3 Láº¦N)\n# =========================================================\n\ndef process_and_split(coverage_name):\n    \"\"\"\n    Thá»±c hiá»‡n toÃ n bá»™ pipeline tá»« Load Vocab Ä‘áº¿n Split cho má»™t má»©c coverage cá»¥ thá»ƒ.\n    coverage_name lÃ  'C90', 'C95', hoáº·c 'C99'.\n    \"\"\"\n    # 1. DYNAMIC FILE PATHS (Dá»±a trÃªn tÃªn coverage_name vÃ  chiáº¿n lÆ°á»£c '_remove')\n    TRAIN_LABEL_FILE = os.path.join(LABEL_DIR, f\"train_data_{coverage_name}_remove.tsv\")\n    VOCAB_FILE = os.path.join(LABEL_DIR, f\"vocab_{coverage_name}_remove.csv\")\n    \n    # 2. OUTPUT FILES\n    OUTPUT_PKL = f\"train_targets_{coverage_name}.pkl\"\n    TRAIN_OUT_IDS = f\"train_ids_{coverage_name}_split.npy\"\n    VAL_OUT_IDS = f\"val_ids_{coverage_name}_split.npy\"\n\n    print(f\"\\n========================================================\")\n    print(f\"ğŸš€ PROCESSING SET: {coverage_name} ({VAL_SIZE*100:.0f}% Validation)\")\n    print(f\"========================================================\")\n\n    # BÆ¯á»šC 1: LOAD VOCAB & Táº O MAP (TERM -> INDEX)\n    print(f\"1. Loading Vocab tá»« {VOCAB_FILE}...\")\n    vocab_df = pd.read_csv(VOCAB_FILE)\n    term_to_idx = {term: i for i, term in enumerate(vocab_df['term'])}\n    num_classes = len(term_to_idx)\n    print(f\"   - Sá»‘ lÆ°á»£ng nhÃ£n (Classes): {num_classes}\")\n\n    # BÆ¯á»šC 2: LOAD EMBEDDING PROTEIN IDs (FILTER INPUT)\n    print(f\"\\n2. Loading Embedding IDs tá»« {TRAIN_IDS_FILE}...\")\n    if TRAIN_IDS_FILE.endswith('.npy'):\n        embed_protein_ids = np.load(TRAIN_IDS_FILE)\n    else:\n        with open(TRAIN_IDS_FILE, 'r') as f:\n            embed_protein_ids = [line.strip() for line in f if line.strip()]\n    \n    valid_proteins_set = set(embed_protein_ids)\n    print(f\"   - Sá»‘ lÆ°á»£ng Protein cÃ³ Embeddings: {len(valid_proteins_set):,}\")\n\n    # BÆ¯á»šC 3: LOAD LABELS & FILTER & MAP\n    print(f\"\\n3. Loading & Processing Labels tá»« {TRAIN_LABEL_FILE}...\")\n    df = pd.read_csv(TRAIN_LABEL_FILE, sep=\"\\t\", names=[\"protein\", \"term\", \"aspect\"])\n    \n    df = df[df['protein'].isin(valid_proteins_set)]\n    df = df[df['term'].isin(term_to_idx)]\n    \n    print(f\"   - Sá»‘ proteins unique há»£p lá»‡: {df['protein'].nunique():,}\")\n\n    # Chuyá»ƒn Ä‘á»•i: GO Term -> Index (Sá»‘ nguyÃªn)\n    df['label_idx'] = df['term'].map(term_to_idx)\n\n    # BÆ¯á»šC 4: Táº O MULTI-HOT DICTIONARY\n    print(\"\\n4. Grouping by Protein (Creating Dictionary)...\")\n    labels_dict = df.groupby('protein')['label_idx'].apply(list).to_dict()\n\n    with open(OUTPUT_PKL, 'wb') as f:\n        pickle.dump(labels_dict, f)\n    print(f\"   âœ… ÄÃ£ lÆ°u targets: {OUTPUT_PKL}\")\n\n    # BÆ¯á»šC 5: CHIA TRAIN / VALIDATION (SPLIT)\n    print(f\"\\n5. Splitting Train/Val...\")\n    all_proteins = np.array(list(labels_dict.keys()))\n\n    train_ids, val_ids = train_test_split(\n        all_proteins, \n        test_size=VAL_SIZE, \n        random_state=SEED,\n        shuffle=True\n    )\n\n    # LÆ°u danh sÃ¡ch ID ra file .npy\n    np.save(TRAIN_OUT_IDS, train_ids)\n    np.save(VAL_OUT_IDS, val_ids)\n\n    print(f\"   âœ… ÄÃ£ lÆ°u file IDs: {TRAIN_OUT_IDS} vÃ  {VAL_OUT_IDS}\")\n    print(f\"   - Train Samples: {len(train_ids):,} | Val Samples: {len(val_ids):,}\")\n\n\n# =========================================================\n# THá»°C THI CHÆ¯Æ NG TRÃŒNH CHÃNH (Táº O 3 Bá»˜)\n# =========================================================\nprint(\"ğŸš€ Báº®T Äáº¦U Táº O 3 Bá»˜ Dá»® LIá»†U Äáº¦U RA...\")\n\nfor name in ['C90', 'C95', 'C99']:\n    process_and_split(name)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"âœ… HOÃ€N Táº¤T! ÄÃƒ Táº O THÃ€NH CÃ”NG 3 Bá»˜ Dá»® LIá»†U Äáº¦U RA.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:39:22.198280Z","iopub.execute_input":"2025-12-04T12:39:22.198724Z","iopub.status.idle":"2025-12-04T12:39:39.184406Z","shell.execute_reply.started":"2025-12-04T12:39:22.198700Z","shell.execute_reply":"2025-12-04T12:39:39.183063Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Báº®T Äáº¦U Táº O 3 Bá»˜ Dá»® LIá»†U Äáº¦U RA...\n\n========================================================\nğŸš€ PROCESSING SET: C90 (10% Validation)\n========================================================\n1. Loading Vocab tá»« /kaggle/input/go-cafa6/vocab_C90_remove.csv...\n   - Sá»‘ lÆ°á»£ng nhÃ£n (Classes): 3375\n\n2. Loading Embedding IDs tá»« /kaggle/input/cafa6-embeds/train_ids.txt...\n   - Sá»‘ lÆ°á»£ng Protein cÃ³ Embeddings: 82,404\n\n3. Loading & Processing Labels tá»« /kaggle/input/go-cafa6/train_data_C90_remove.tsv...\n   - Sá»‘ proteins unique há»£p lá»‡: 82,401\n\n4. Grouping by Protein (Creating Dictionary)...\n   âœ… ÄÃ£ lÆ°u targets: train_targets_C90.pkl\n\n5. Splitting Train/Val...\n   âœ… ÄÃ£ lÆ°u file IDs: train_ids_C90_split.npy vÃ  val_ids_C90_split.npy\n   - Train Samples: 74,160 | Val Samples: 8,241\n\n========================================================\nğŸš€ PROCESSING SET: C95 (10% Validation)\n========================================================\n1. Loading Vocab tá»« /kaggle/input/go-cafa6/vocab_C95_remove.csv...\n   - Sá»‘ lÆ°á»£ng nhÃ£n (Classes): 6413\n\n2. Loading Embedding IDs tá»« /kaggle/input/cafa6-embeds/train_ids.txt...\n   - Sá»‘ lÆ°á»£ng Protein cÃ³ Embeddings: 82,404\n\n3. Loading & Processing Labels tá»« /kaggle/input/go-cafa6/train_data_C95_remove.tsv...\n   - Sá»‘ proteins unique há»£p lá»‡: 82,402\n\n4. Grouping by Protein (Creating Dictionary)...\n   âœ… ÄÃ£ lÆ°u targets: train_targets_C95.pkl\n\n5. Splitting Train/Val...\n   âœ… ÄÃ£ lÆ°u file IDs: train_ids_C95_split.npy vÃ  val_ids_C95_split.npy\n   - Train Samples: 74,161 | Val Samples: 8,241\n\n========================================================\nğŸš€ PROCESSING SET: C99 (10% Validation)\n========================================================\n1. Loading Vocab tá»« /kaggle/input/go-cafa6/vocab_C99_remove.csv...\n   - Sá»‘ lÆ°á»£ng nhÃ£n (Classes): 15582\n\n2. Loading Embedding IDs tá»« /kaggle/input/cafa6-embeds/train_ids.txt...\n   - Sá»‘ lÆ°á»£ng Protein cÃ³ Embeddings: 82,404\n\n3. Loading & Processing Labels tá»« /kaggle/input/go-cafa6/train_data_C99_remove.tsv...\n   - Sá»‘ proteins unique há»£p lá»‡: 82,404\n\n4. Grouping by Protein (Creating Dictionary)...\n   âœ… ÄÃ£ lÆ°u targets: train_targets_C99.pkl\n\n5. Splitting Train/Val...\n   âœ… ÄÃ£ lÆ°u file IDs: train_ids_C99_split.npy vÃ  val_ids_C99_split.npy\n   - Train Samples: 74,163 | Val Samples: 8,241\n\n==================================================\nâœ… HOÃ€N Táº¤T! ÄÃƒ Táº O THÃ€NH CÃ”NG 3 Bá»˜ Dá»® LIá»†U Äáº¦U RA.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport pandas as pd\nimport os\n\n# Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n\nTARGET_PKL = \"/kaggle/working/train_targets_C95.pkl\"\n\n# 1. Load targets dictionary\nprint(f\"Äang Ä‘á»c file targets: {TARGET_PKL}...\")\nwith open(TARGET_PKL, 'rb') as f:\n    labels_dict = pickle.load(f)\n\n# 2. Load Vocab (Ä‘á»ƒ dá»‹ch index)\nprint(f\"Äang Ä‘á»c file vocab: {VOCAB_FILE}...\")\nvocab_df = pd.read_csv(VOCAB_FILE)\nterm_list = vocab_df['term'].tolist()\naspect_list = vocab_df['aspect'].tolist()\n\n# 3. Láº¥y máº«u vÃ  kiá»ƒm tra\nsample_id = list(labels_dict.keys())[0]\nsample_indices = labels_dict[sample_id]\nnum_classes = len(term_list)\n\nprint(\"\\n--- KIá»‚M TRA MáºªU ---\")\nprint(f\"Protein ID: {sample_id}\")\nprint(f\"Sá»‘ lÆ°á»£ng nhÃ£n dÆ°Æ¡ng: {len(sample_indices)}\")\nprint(f\"Total classes: {num_classes}\")\n\n# 4. Dá»‹ch cÃ¡c chá»‰ sá»‘ thÃ nh GO Term vÃ  Aspect\nprint(\"\\nDanh sÃ¡ch nhÃ£n GO (dá»‹ch tá»« Index):\")\nfor idx in sample_indices:\n    term = term_list[idx]\n    aspect = aspect_list[idx]\n    print(f\"  - Index {idx:<5} -> {term:<12} (Aspect: {aspect})\")\n\n# 5. Kiá»ƒm tra dáº¡ng Multi-hot (chuyá»ƒn Ä‘á»•i)\n# Táº¡o vector 0/1 dÃ i 6416 sá»‘\nmulti_hot_vector = np.zeros(num_classes, dtype=np.int8)\nmulti_hot_vector[sample_indices] = 1\n\nprint(f\"\\nVector Multi-hot (vÃ­ dá»¥): {multi_hot_vector[:10]}...\")\n\nmulti_hot_vector.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:36:53.483000Z","iopub.execute_input":"2025-12-04T12:36:53.484334Z","iopub.status.idle":"2025-12-04T12:36:53.769605Z","shell.execute_reply.started":"2025-12-04T12:36:53.484292Z","shell.execute_reply":"2025-12-04T12:36:53.768537Z"}},"outputs":[{"name":"stdout","text":"Äang Ä‘á»c file targets: /kaggle/working/train_targets_C95.pkl...\nÄang Ä‘á»c file vocab: /kaggle/input/go-cafa6/vocab_C95_remove.csv...\n\n--- KIá»‚M TRA MáºªU ---\nProtein ID: A0A023FBW4\nSá»‘ lÆ°á»£ng nhÃ£n dÆ°Æ¡ng: 4\nTotal classes: 6413\n\nDanh sÃ¡ch nhÃ£n GO (dá»‹ch tá»« Index):\n  - Index 3     -> GO:0005488   (Aspect: MFO)\n  - Index 4449  -> GO:0019956   (Aspect: MFO)\n  - Index 2121  -> GO:0019955   (Aspect: MFO)\n  - Index 6     -> GO:0005515   (Aspect: MFO)\n\nVector Multi-hot (vÃ­ dá»¥): [0 0 0 1 0 0 1 0 0 0]...\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(6413,)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}