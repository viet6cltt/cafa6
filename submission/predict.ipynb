{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98aa1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading Taxonomy Mapping...\n",
      " NUM_TAXA loaded from PKL = 135\n",
      "Taxon stats: min = 0 max = 134\n",
      " Loading Vocab & Maps...\n",
      "Loading model: /root/cafa6/c95/final_cafa6_model_c95.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: /root/cafa6/c99/final_cafa6_model_c99.pth\n",
      " Predicting 224309 proteins with Batch Size 1024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [04:12<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SUBMISSION READY: submission_c95_c99_final.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "CONFIG = {\n",
    "    \"TEST_IDS\": \"/root/CAFA6data/cafa6-embeds/test_ids.txt\",\n",
    "    \"TEST_EMBEDS\": \"/root/CAFA6data/cafa6-embeds/test_embeds.npy\",\n",
    "\n",
    "    \"VOCAB_C95\": \"/root/CAFA6data/c95/vocab_C95_remove.csv\",\n",
    "    \"VOCAB_C99\": \"/root/CAFA6data/c99/vocab_C99_remove.csv\",\n",
    "    \"IA_FILE\": \"/root/CAFA6data/IA.tsv\",\n",
    "\n",
    "    \"MODEL_C95\": \"/root/cafa6/c95/final_cafa6_model_c95.pth\",\n",
    "    \"MODEL_C99\": \"/root/cafa6/c99/final_cafa6_model_c99.pth\",\n",
    "\n",
    "    \"top_k\": 500,\n",
    "    \"threshold\": 0.001,\n",
    "    \"output_file\": \"submission_c95_c99_final.tsv\",\n",
    "\n",
    "    \"device\": \"cuda\",\n",
    "    \"batch_size\": 1024,  \n",
    "    \"num_workers\": 8,   \n",
    "\n",
    "    \"TAXON_PKL\": \"/root/cafa6/preprocessing/taxon_mapping_K_Species.pkl\"\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# MODEL\n",
    "# =========================================================\n",
    "class WideProteinMLP_WithTaxon(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_taxa, taxon_dim=64,\n",
    "                 hidden_dims=[4096, 4096], dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.seq_norm = nn.LayerNorm(input_dim)\n",
    "        self.taxon_embedding = nn.Embedding(num_taxa, taxon_dim)\n",
    "        self.taxon_norm = nn.LayerNorm(taxon_dim)\n",
    "\n",
    "        layers = []\n",
    "        prev = input_dim + taxon_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(prev, h), nn.GELU(), nn.Dropout(dropout)]\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, num_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, seq, tax):\n",
    "        x = torch.cat([self.seq_norm(seq), self.taxon_norm(self.taxon_embedding(tax))], dim=1)\n",
    "        return self.net(x)\n",
    "\n",
    "# =========================================================\n",
    "# DATASET\n",
    "# =========================================================\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, ids_path, embeds_path, taxon_pkl):\n",
    "        with open(ids_path) as f:\n",
    "            self.ids = [x.strip() for x in f]\n",
    "\n",
    "        self.embeds = np.load(embeds_path, mmap_mode=\"r\")\n",
    "\n",
    "        with open(taxon_pkl, \"rb\") as f:\n",
    "            tax = pickle.load(f)\n",
    "        self.tax_map = tax[\"prot_to_taxon_idx\"]\n",
    "        self.num_taxa = tax[\"num_taxa_classes\"]\n",
    "        self.default_tax = self.num_taxa - 1\n",
    "\n",
    "\n",
    "    def __len__(self): return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        pid = self.ids[i]\n",
    "        feat = torch.tensor(self.embeds[i], dtype=torch.float32)\n",
    "\n",
    "        tax = self.tax_map.get(pid, self.default_tax)\n",
    "        return feat, torch.tensor(tax, dtype=torch.long), pid\n",
    "\n",
    "# =========================================================\n",
    "# LOAD MODEL\n",
    "# =========================================================\n",
    "def load_model(path, n_cls, num_taxa, dropout, device):\n",
    "    print(f\"Loading model: {path}\")\n",
    "    model = WideProteinMLP_WithTaxon(\n",
    "        1280, n_cls, num_taxa, dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "def main():\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    device = CONFIG[\"device\"]\n",
    "    \n",
    "    print(\" Loading Taxonomy Mapping...\")\n",
    "    with open(CONFIG[\"TAXON_PKL\"], \"rb\") as f:\n",
    "        tax_data = pickle.load(f)\n",
    "\n",
    "    NUM_TAXA = tax_data[\"num_taxa_classes\"]\n",
    "    print(f\" NUM_TAXA loaded from PKL = {NUM_TAXA}\")\n",
    "    \n",
    "    print(\"Taxon stats:\",\n",
    "      \"min =\", min(tax_data[\"prot_to_taxon_idx\"].values()),\n",
    "      \"max =\", max(tax_data[\"prot_to_taxon_idx\"].values()))\n",
    "\n",
    "    print(\" Loading Vocab & Maps...\")\n",
    "    df95 = pd.read_csv(CONFIG[\"VOCAB_C95\"])\n",
    "    df99 = pd.read_csv(CONFIG[\"VOCAB_C99\"])\n",
    "    \n",
    "    terms95 = df95.term.tolist()\n",
    "    terms99 = np.array(df99.term.tolist()) \n",
    "\n",
    "    # Map indices\n",
    "    t99_idx = {t: i for i, t in enumerate(terms99)}\n",
    "    src95, dst99 = zip(*[(i, t99_idx[t]) for i, t in enumerate(terms95) if t in t99_idx])\n",
    "    src95 = torch.tensor(src95, device=device)\n",
    "    dst99 = torch.tensor(dst99, device=device)\n",
    "\n",
    "    # IA Vector\n",
    "    ia_df = pd.read_csv(CONFIG[\"IA_FILE\"], sep=\"\\t\", header=None, names=[\"term\", \"ia\"])\n",
    "    ia_map = dict(zip(ia_df.term, ia_df.ia))\n",
    "    ia_vec = torch.tensor([ia_map.get(t, 0.0) for t in terms99], device=device)\n",
    "\n",
    "    # --- Load Models ---\n",
    "    m95 = load_model(CONFIG[\"MODEL_C95\"], len(terms95), NUM_TAXA, 0.4, device)\n",
    "    m99 = load_model(CONFIG[\"MODEL_C99\"], len(terms99), NUM_TAXA, 0.25, device)\n",
    "\n",
    "    # --- DataLoader Optimized ---\n",
    "    dataset = TestDataset(CONFIG[\"TEST_IDS\"], CONFIG[\"TEST_EMBEDS\"], CONFIG[\"TAXON_PKL\"])\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG[\"num_workers\"],\n",
    "        pin_memory=True,                  \n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "    # Xóa file cũ nếu có\n",
    "    if os.path.exists(CONFIG[\"output_file\"]):\n",
    "        os.remove(CONFIG[\"output_file\"])\n",
    "\n",
    "    print(f\" Predicting {len(dataset)} proteins with Batch Size {CONFIG['batch_size']}...\")\n",
    "    \n",
    "    # --- Inference Loop ---\n",
    "    with torch.inference_mode():\n",
    "        for feats, tax, pids in tqdm(loader):\n",
    "            feats, tax = feats.to(device, non_blocking=True), tax.to(device, non_blocking=True)\n",
    "\n",
    "            with autocast(\"cuda\"):\n",
    "               \n",
    "                p99 = torch.sigmoid(m99(feats, tax))\n",
    "                p95_raw = torch.sigmoid(m95(feats, tax))\n",
    "\n",
    "                # Mapping C95 -> C99 Space\n",
    "                p95 = torch.zeros_like(p99)\n",
    "                p95[:, dst99] = p95_raw[:, src95]\n",
    "\n",
    "                ia = ia_vec.unsqueeze(0)  # [1, C]\n",
    "\n",
    "                # -------------------------\n",
    "                # ZONE 1: IA < 2  (SAFE)\n",
    "                # -------------------------\n",
    "                mask_z1 = ia < 2.0\n",
    "                prob_z1 = 0.95 * p95 + 0.05 * p99\n",
    "\n",
    "                # -------------------------\n",
    "                # ZONE 2: 2 <= IA < 4  (BATTLE)\n",
    "                # -------------------------\n",
    "                mask_z2 = (ia >= 2.0) & (ia < 4.0)\n",
    "\n",
    "                better_c99_z2 = p99 > (p95 + 0.08)\n",
    "\n",
    "                prob_z2 = torch.where(\n",
    "                    better_c99_z2,\n",
    "                    0.45 * p95 + 0.55 * p99,   \n",
    "                    0.60 * p95 + 0.40 * p99    \n",
    "                )\n",
    "\n",
    "                # -------------------------\n",
    "                # ZONE 3: IA >= 4  \n",
    "                # -------------------------\n",
    "                mask_z3 = ia >= 4.0\n",
    "\n",
    "                # Base (khi C99 không vượt trội)\n",
    "                prob_z3_base = 0.20 * p95 + 0.80 * p99\n",
    "\n",
    "                # Strong signal từ C99 \n",
    "                prob_z3_strong = 0.85 * p99 + 0.15 * p95\n",
    "\n",
    "                better_c99_z3 = p99 > (p95 + 0.05)\n",
    "\n",
    "                prob_z3 = torch.where(\n",
    "                    better_c99_z3,\n",
    "                    prob_z3_strong,\n",
    "                    prob_z3_base\n",
    "                )\n",
    "\n",
    "                # -------------------------\n",
    "                # COMBINE ALL ZONES\n",
    "                # -------------------------\n",
    "                p_final = (\n",
    "                    prob_z1 * mask_z1 +\n",
    "                    prob_z2 * mask_z2 +\n",
    "                    prob_z3 * mask_z3\n",
    "                )\n",
    "\n",
    "            # --- POST-PROCESSING (VECTORIZED) ---\n",
    "            p_final[p_final < CONFIG[\"threshold\"]] = 0.0\n",
    "\n",
    "            # 2. Top-K \n",
    "            top_vals, top_inds = torch.topk(p_final, CONFIG[\"top_k\"], dim=1)\n",
    "\n",
    "            # 3. Move to CPU \n",
    "            vals_np = top_vals.cpu().numpy() # [B, K]\n",
    "            inds_np = top_inds.cpu().numpy() # [B, K]\n",
    "            \n",
    "            # --- OUTPUT WRITING ---\n",
    "            \n",
    "            vals_flat = vals_np.flatten()\n",
    "            inds_flat = inds_np.flatten()\n",
    "            \n",
    "\n",
    "            pids_list = np.array(pids)\n",
    "            pids_flat = np.repeat(pids_list, CONFIG[\"top_k\"])\n",
    "            \n",
    "            valid_mask = vals_flat > 0\n",
    "            \n",
    "            if not np.any(valid_mask):\n",
    "                continue \n",
    "            \n",
    "            # Lọc dữ liệu hợp lệ\n",
    "            final_pids = pids_flat[valid_mask]\n",
    "            final_inds = inds_flat[valid_mask]\n",
    "            final_vals = vals_flat[valid_mask]\n",
    "            \n",
    "            # Map Index -> Term String (Vectorized Lookup)\n",
    "            final_terms = terms99[final_inds]\n",
    "            \n",
    "            df_batch = pd.DataFrame({\n",
    "                'id': final_pids,\n",
    "                'term': final_terms,\n",
    "                'score': final_vals\n",
    "            })\n",
    "            \n",
    "            df_batch.to_csv(\n",
    "                CONFIG[\"output_file\"], \n",
    "                sep='\\t', \n",
    "                header=False, \n",
    "                index=False, \n",
    "                mode='a', \n",
    "                float_format='%.3f'\n",
    "            )\n",
    "\n",
    "    print(\" SUBMISSION READY:\", CONFIG[\"output_file\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
